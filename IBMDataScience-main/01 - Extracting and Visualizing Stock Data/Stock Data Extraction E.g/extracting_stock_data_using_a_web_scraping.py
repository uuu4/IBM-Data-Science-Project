# -*- coding: utf-8 -*-
"""Extracting_Stock_Data_Using_a_Web_Scraping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1STPxqAk3p4wDyrvvMloRSxswxe9pDdqh

<a href="https://colab.research.google.com/github/marcoshsq/Stocks_Market_Data_Analysis/blob/main/Extracting_Stock_Data_Using_a_Web_Scraping.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

# Extracting Stock Data Using a Web Scraping
"""

#!pip install pandas==1.3.3
#!pip install requests==2.26.0
!mamba install bs4==4.10.0 -y
!mamba install html5lib==1.1 -y
!pip install lxml==4.6.4
#!pip install plotly==5.3.1

import pandas as pd
import requests
from bs4 import BeautifulSoup

"""# Using Webscraping to Extract Stock Data Example

First we must use the request library to downlaod the webpage, and extract the text. We will extract Netflix stock data https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/netflix_data_webpage.html.
"""

url = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/netflix_data_webpage.html"

data  = requests.get(url).text

"""Next we must parse the text into html using beautiful_soup"""

soup = BeautifulSoup(data, 'html5lib')

"""Now we can turn the html table into a pandas dataframe


"""

netflix_data = pd.DataFrame(columns=["Date", "Open", "High", "Low", "Close", "Volume"])

# First we isolate the body of the table which contains all the information
# Then we loop through each row and find all the column values for each row
for row in soup.find("tbody").find_all('tr'):
    col = row.find_all("td")
    date = col[0].text
    Open = col[1].text
    high = col[2].text
    low = col[3].text
    close = col[4].text
    adj_close = col[5].text
    volume = col[6].text
    
    # Finally we append the data of each row to the table
    netflix_data = netflix_data.append({"Date":date, "Open":Open, "High":high, "Low":low, "Close":close, "Adj Close":adj_close, "Volume":volume}, ignore_index=True)

"""We can now print out the dataframe


"""

netflix_data.head()

"""We can also use the pandas read_html function using the url


"""

read_html_pandas_data = pd.read_html(url)

"""Or we can convert the BeautifulSoup object to a string


"""

read_html_pandas_data = pd.read_html(str(soup))

"""Beacause there is only one table on the page, we just take the first table in the list returned


"""

netflix_dataframe = read_html_pandas_data[0]

netflix_dataframe.head()